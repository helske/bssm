---
title: "Replications"
author: "Jouni Helske"
date: "11/17/2021"
output: html_document
---

```{r srr-tags, eval = FALSE, echo = FALSE}
#' @srrstats {G.5.4, G5.4a, G5.4b, G5.4c, G5.5, G5.6, G5.6a, G5.6b, G5.7} The 
#' algorithms work correctly as per Vihola, Helske, Franks (2020) 
#' (all simulations were implemented with the bssm package) and Helske 
#' and Vihola (2021).
#' @srrstats {G5.4} **Correctness tests** *to test that statistical algorithms produce expected results to some fixed test data sets (potentially through comparisons using binding frameworks such as [RStata](https://github.com/lbraglia/RStata)).*
#' @srrstats {G5.4a} *For new methods, it can be difficult to separate out correctness of the method from the correctness of the implementation, as there may not be reference for comparison. In this case, testing may be implemented against simple, trivial cases or against multiple implementations such as an initial R implementation compared with results from a C/C++ implementation.*
#' @srrstats {G5.4b} *For new implementations of existing methods, correctness tests should include tests against previous implementations. Such testing may explicitly call those implementations in testing, preferably from fixed-versions of other software, or use stored outputs from those where that is not possible.*
#' @srrstats {G5.4c} *Where applicable, stored values may be drawn from published paper outputs when applicable and where code from original implementations is not available*
#' @srrstats {G5.5} *Correctness tests should be run with a fixed random seed*
#' @srrstats {G5.6} **Parameter recovery tests** *to test that the implementation produce expected results given data with known properties. For instance, a linear regression algorithm should return expected coefficient values for a simulated data set generated from a linear model.*
#' @srrstats {G5.6a} *Parameter recovery tests should generally be expected to succeed within a defined tolerance rather than recovering exact values.*
#' @srrstats {G5.6b} *Parameter recovery tests should be run with multiple random seeds when either data simulation or the algorithm contains a random component. (When long-running, such tests may be part of an extended, rather than regular, test suite; see G4.10-4.12, below).*
#' @srrstats {G5.7} **Algorithm performance tests** *to test that implementation performs as expected as properties of data change. For instance, a test may show that parameters approach correct estimates within tolerance as data size increases, or that convergence times decrease for higher convergence thresholds.*
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Reproducing some of the results of IS-MCMC paper

Full simulation experiments of Vihola, Helske and Franks (2020) takes some time, 
here we only run a single replication to test that the methods work as expected. 
To generate Table 1 in the paper, the code below should be run say 1000 times, 
from which IREs could be computed.

```{r, cache = TRUE}
library("bssm")
data(poisson_series)
s <- sd(log(pmax(0.1, poisson_series)))
model <- bsm_ng(poisson_series, sd_level = uniform(0.115, 0, 2 * s),
  sd_slope = uniform(0.004, 0, 2 * s), P1 = diag(0.1, 2), distribution = "poisson")


d <- data.frame(mean = NA, se = NA,
  variable = c("sd_level", "sd_slope", "u_1", "u_100"),
  mcmc_type = rep(c("approx", "da", "is1", "is2", "pm"),
    times = 4*c(2, 6, 6, 6, 6)),
  sampling_method = c(rep("psi", 8),
    rep(rep(c("bsf", "spdk", "psi"), each = 2 * 4), 4)),
  local_approx = rep(c(TRUE, FALSE), each = 4),
  time = NA,
  acceptance_rate = NA)

iter <- 1e4 # Use less iterations than in the paper for faster experiment
for(i in seq(1, nrow(d), by = 4)) {
  
  cat("Testing method '", d$mcmc_type[i], "' with sampling by '", 
    d$sampling_method[i], "' and local_approx '", d$local_approx[i], "'\n", 
    sep = "")
  
  res <- run_mcmc(model, iter = iter,
    sampling_method = d$sampling_method[i],
    particles = switch(d$sampling_method[i],
      bsf = 200,
      spdk = 10,
      psi = 10),
    mcmc_type = d$mcmc_type[i],
    local_approx = d$local_approx[i],
    end_adaptive_phase = TRUE)
  
  w <- res$counts * 
    if (res$mcmc_type %in% paste0("is", 1:2)) res$weights else 1
  
  d[((i - 1) + 1):((i - 1) + 4), "mean"] <- c(
    diagis::weighted_mean(res$theta, w),
    diagis::weighted_mean(res$alpha[1, 1, ], w),
    diagis::weighted_mean(res$alpha[100, 1, ], w))
  
  d[((i - 1) + 1):((i - 1) + 4), "se"] <- c(
    sqrt(asymptotic_var(res$theta[, 1], w)),
    sqrt(asymptotic_var(res$theta[, 2], w)),
    sqrt(asymptotic_var(res$alpha[1, 1, ], w)),
    sqrt(asymptotic_var(res$alpha[100, 1, ], w)))
  
  d$time[((i - 1) + 1):((i - 1) + 4)] <- res$time["elapsed"]
  d$acceptance_rate[((i - 1) + 1):((i - 1) + 4)] <- res$acceptance_rate
}
```
Results:
```{r}
library(dplyr)
d %>% 
    arrange(local_approx, variable, mcmc_type, sampling_method)
```

