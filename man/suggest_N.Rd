% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/post_correction.R
\name{suggest_N}
\alias{suggest_N}
\title{Suggest Number of Particles for \eqn{\psi}-APF Post-correction}
\usage{
suggest_N(
  model,
  mcmc_output,
  candidates = seq(10, 100, by = 10),
  replications = 100,
  seed = sample(.Machine$integer.max, size = 1)
)
}
\arguments{
\item{model}{Model of class \code{nongaussian} or \code{ssm_nlg}.}

\item{mcmc_output}{An output from \code{run_mcmc} used to compute the MAP 
estimate of theta. While the intended use assumes this is from 
approximate MCMC, it is not actually checked, i.e., 
it is also possible to input previous (asymptotically) exact output.}

\item{candidates}{Vector containing the candidate number of particles to 
test. Default is \code{seq(10, 100, by = 10)}.}

\item{replications}{How many replications should be used for computing 
the standard deviations? Default is 100.}

\item{seed}{Seed for the random number generator.}
}
\value{
List with suggested number of particles \code{N} and matrix 
containing estimated standard deviations of the log-weights and 
corresponding number of particles.
}
\description{
Function \code{estimate_N} estimates suitable number particles needed for 
accurate post-correction of approximate MCMC.
}
\details{
Function \code{suggest_N} estimates the standard deviation of the 
logarithm of the post-correction weights at approximate MAP of theta, 
using various particle sizes and suggest smallest number of particles 
which still leads standard deviation less than 1. Similar approach was 
suggested in the context of pseudo-marginal MCMC by Doucet et al. (2015),
 but see also Section 10.3 in Vihola et al (2020).
}
\examples{
\donttest{
set.seed(1)
n <- 300
x1 <- sin((2 * pi / 12) * 1:n)
x2 <- cos((2 * pi / 12) * 1:n)
alpha <- numeric(n)
alpha[1] <- 0
rho <- 0.7
sigma <- 2
mu <- 1
for(i in 2:n) {
  alpha[i] <- rnorm(1, mu * (1 - rho) + rho * alpha[i-1], sigma)
}
u <- rpois(n, 50)
y <- rbinom(n, size = u, plogis(0.5 * x1 + x2 + alpha))

ts.plot(y / u)

model <- ar1_ng(y, distribution = "binomial", 
  rho = uniform(0.5, -1, 1), sigma = gamma_prior(1, 2, 0.001),
  mu = normal(0, 0, 10),
  xreg = cbind(x1,x2), beta = normal(c(0, 0), 0, 5),
  u = u)

out_approx <- run_mcmc(model, mcmc_type = "approx", 
 iter = 5000)

estN <- suggest_N(model, out_approx, candidates = seq(10, 50, by = 10))
plot(x = estN$results$N, y = estN$results$sd, type = "b")
estN$N
}
}
\references{
Doucet, A, Pitt, MK, Deligiannidis, G, Kohn, R (2015). 
Efficient implementation of Markov chain Monte Carlo when using an 
unbiased likelihood estimator, Biometrika, 102(2) p. 295-313,
https://doi.org/10.1093/biomet/asu075

Vihola, M, Helske, J, Franks, J (2020). Importance sampling type estimators 
based on approximate marginal Markov chain Monte Carlo. 
Scand J Statist. 1-38. https://doi.org/10.1111/sjos.12492
}
