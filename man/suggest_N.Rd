% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/post_correction.R
\name{suggest_N}
\alias{suggest_N}
\title{Suggest Number of Particles for \eqn{\psi}-APF Post-correction}
\usage{
suggest_N(
  model,
  theta,
  candidates = seq(10, 100, by = 10),
  replications = 100,
  seed = sample(.Machine$integer.max, size = 1)
)
}
\arguments{
\item{model}{Model of class \code{nongaussian} or \code{ssm_nlg}.}

\item{theta}{A vector of theta corresponding to the model, at which point 
the standard deviation of the log-likelihood is computed. Typically MAP 
estimate from the (approximate) MCMC run. Can also be an output from 
\code{run_mcmc} which is then used to compute the MAP 
estimate of theta.}

\item{candidates}{Vector of positive integers containing the candidate 
number of particles to test. Default is \code{seq(10, 100, by = 10)}.}

\item{replications}{Positive integer, how many replications should be used 
for computing the standard deviations? Default is 100.}

\item{seed}{Seed for the random number generator  (positive integer).}
}
\value{
List with suggested number of particles \code{N} and matrix 
containing estimated standard deviations of the log-weights and 
corresponding number of particles.
}
\description{
Function \code{estimate_N} estimates suitable number particles needed for 
accurate post-correction of approximate MCMC.
}
\details{
Function \code{suggest_N} estimates the standard deviation of the 
logarithm of the post-correction weights at approximate MAP of theta, 
using various particle sizes and suggest smallest number of particles 
which still leads standard deviation less than 1. Similar approach was 
suggested in the context of pseudo-marginal MCMC by Doucet et al. (2015),
 but see also Section 10.3 in Vihola et al (2020).
}
\examples{

set.seed(1)
n <- 300
x1 <- sin((2 * pi / 12) * 1:n)
x2 <- cos((2 * pi / 12) * 1:n)
alpha <- numeric(n)
alpha[1] <- 0
rho <- 0.7
sigma <- 1.2
mu <- 1
for(i in 2:n) {
  alpha[i] <- rnorm(1, mu * (1 - rho) + rho * alpha[i-1], sigma)
}
u <- rpois(n, 50)
y <- rbinom(n, size = u, plogis(0.5 * x1 + x2 + alpha))

ts.plot(y / u)

model <- ar1_ng(y, distribution = "binomial", 
  rho = uniform(0.5, -1, 1), sigma = gamma_prior(1, 2, 0.001),
  mu = normal(0, 0, 10),
  xreg = cbind(x1,x2), beta = normal(c(0, 0), 0, 5),
  u = u)

# theta from earlier approximate MCMC run
# out_approx <- run_mcmc(model, mcmc_type = "approx", 
#   iter = 5000) 
# theta <- out_approx$theta[which.max(out_approx$posterior), ]

theta <- c(rho = 0.64, sigma = 1.16, mu = 1.1, x1 = 0.56, x2 = 1.28)

estN <- suggest_N(model, theta, candidates = seq(10, 50, by = 10),
  replications = 50, seed = 1)
plot(x = estN$results$N, y = estN$results$sd, type = "b")
estN$N

}
\references{
Doucet, A, Pitt, MK, Deligiannidis, G, Kohn, R (2015). 
Efficient implementation of Markov chain Monte Carlo when using an 
unbiased likelihood estimator, Biometrika, 102(2) p. 295-313,
https://doi.org/10.1093/biomet/asu075

Vihola, M, Helske, J, Franks, J (2020). Importance sampling type estimators 
based on approximate marginal Markov chain Monte Carlo. 
Scand J Statist. 1-38. https://doi.org/10.1111/sjos.12492
}
